{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b158ef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01413c40",
   "metadata": {},
   "source": [
    "# 1. Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abb5af72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\DELL Inspiron/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-7-13 Python-3.8.10 torch-1.8.2+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "Video_Path = 'C:/Users/DELL Inspiron/Desktop/Computer Vision Projects/vehicles_counting-master/vehicles_counting-master/highway.mp4'\n",
    "cap = cv2.VideoCapture(Video_Path)\n",
    "width = int(cap.get(3))\n",
    "height = int(cap.get(4))\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "#START_TRACKING_LINE = [(0, int(height/4)), end_point = (width, height/4), color = (0, 255, 0), thickness =3)\n",
    "#CONFIRMATION_LINE = dict(start_point = (0, height - 50), end_point = (width, height - 50), color = (0, 255, 0), thickness =3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39967b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_determiner(x1, y1, x2, y2):\n",
    "    x_centre = int((x1+ x2)/2)\n",
    "    y_centre = int((y1 + y2)/2)\n",
    "    return (x_centre, y_centre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "559bd183",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    cv2.line(frame, (0, height - 75), ( width, height - 75), (0, 255, 0), 1)\n",
    "    cv2.imshow('Real-Time', frame)\n",
    "    if cv2.waitKey(10) & 0xff == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16fc4a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('capture.png')\n",
    "result = model(image)\n",
    "len(result.xyxy[0])\n",
    "tracking_points = []\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50ef7a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(result.xyxy[0])):\n",
    "    x1, y1, x2, y2 = result.xyxy[0][i][0], result.xyxy[0][i][1], result.xyxy[0][i][2], result.xyxy[0][i][3]\n",
    "    center = center_determiner(x1, y1, x2, y2)\n",
    "    tracking_points.append(center)\n",
    "    cv2.circle(image, center, 4, (0, 255, 0), 2)\n",
    "    for tracking_point in tracking_points:\n",
    "        if tracking_point[1] > image.shape[0] -75:\n",
    "            count += 1\n",
    "            tracking.points.remove(tracking_point)\n",
    "cv2.line(image, (0, image.shape[0] - 75), ( image.shape[1], image.shape[0] - 75), (0, 255, 0), 1)\n",
    "cv2.imshow('image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "943efaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_points = []\n",
    "count = 0\n",
    "Video_Path = 'C:/Users/DELL Inspiron/Desktop/Computer Vision Projects/vehicles_counting-master/vehicles_counting-master/highway.mp4'\n",
    "cap = cv2.VideoCapture(Video_Path)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    result = model(frame)\n",
    "    for i in range(len(result.xyxy[0])):\n",
    "        x1, y1, x2, y2 = result.xyxy[0][i][0], result.xyxy[0][i][1], result.xyxy[0][i][2], result.xyxy[0][i][3]\n",
    "        center = center_determiner(x1, y1, x2, y2)\n",
    "        tracking_points.append(center)\n",
    "        cv2.circle(frame, center, 4, (0, 255, 0), 2)\n",
    "    for tracking_point in tracking_points:\n",
    "        if tracking_point[1] > height -75:\n",
    "            count += 1\n",
    "            tracking_points.remove(tracking_point)\n",
    "    cv2.line(frame, (0, height - 75), ( width, height - 75), (0, 255, 0), 1)\n",
    "    cv2.putText(frame, str(count), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Real-Time', frame)\n",
    "    if cv2.waitKey(10) & 0xff == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed975dab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
